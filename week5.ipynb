{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f23e8e",
   "metadata": {},
   "source": [
    "**GRADIENT DESCENT ALGORITM**\n",
    "\n",
    "> 일단 $\\theta$의 초기값을 랜덤하게 선정하고  \n",
    "Cost Function $J(\\theta)$가 <mark>줄어드는 방향</mark>으로 $\\theta$ 값을 계속 바꾸어 나가며\n",
    "$J(\\theta)$ 값이 <mark>최소</mark>가 될 때 알고리즘을 종료  \n",
    "\n",
    "> 수렴할 때까지 반복\n",
    "    $\\theta := \\theta - \\alpha$  \n",
    "    학습률 $\\alpha$는 현재 $\\theta$ 값에서의 기울기  \n",
    "    학습률이란 위 식에서 얼마만큼 $\\theta$를 업데이트 할 것인지 설정하는 값\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e76b12",
   "metadata": {},
   "source": [
    "**Multavariate Linear Regression**\n",
    "> 입력 변수가 여러개라면 Multivariate Linear Regression 문제로 일반화 가능  \n",
    "\n",
    "> 입력 변수가 4개면 $h_\\theta(x)=\\theta^Tx$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9fac98",
   "metadata": {},
   "source": [
    "**Classification = Logistic Regression**\n",
    "> 분류 문제는 0 또는 1로 예측  \n",
    "예측값 $h_\\theta(x)$가 항상 0에서 1 사이의 값을 갖도록 Hypothesis 함수 수정  \n",
    "\n",
    ">$h_\\theta(x) = g({\\theta_0 + \\theta_1}x)$  \n",
    "$g(z) = {1 \\over 1 + e^-z}$  \n",
    "\n",
    "> Convex Cost Function을 이용하여 h의 파라미터 $\\theta_0$와 $\\theta_1$을 찾는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e29a7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlex",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
